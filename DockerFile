# Use an official Python runtime as a base image
# syntax=docker/dockerfile:1.4
FROM nvidia/cuda:11.8.0-devel-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=UTC

# Install system dependencies
RUN apt-get update && \
    apt-get install -y --fix-missing --no-install-recommends \
    libgl1-mesa-dev \
    python3-pip \
    git \
    curl \
    wget \
    gcc \
    libssl-dev \
    build-essential \
    libglib2.0-0 \
    libxrender1 \
    libglx-mesa0 \
    libgl1 \
    llvm \
    lldb \
    llvm-dev \
    llvm-runtime \
    libgl1-mesa-glx \
    libgl1-mesa-dri \
    libosmesa6 \
    xvfb \
    libglu1-mesa \
    libxinerama1 \
    libxcursor1 \
    libglew-dev \
    libglfw3-dev \
    libgl1-mesa-dev \
    python3 \
    python3-dev \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# Set the working directory in the container
WORKDIR /app

# Copy requirements file and install dependencies
COPY requirements.txt /app/requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# Copy the entire source code and configs
COPY ./src /app/src
COPY ./configs /app/configs
COPY ./weights /app/weights

# Set the default command for running FastAPI or inference
CMD ["uvicorn", "src.app.main:app", "--host", "0.0.0.0", "--port", "8000"]
